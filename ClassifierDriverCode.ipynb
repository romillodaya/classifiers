{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ClassifierDriverCode.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"eGhmdCnJstyP","executionInfo":{"status":"ok","timestamp":1616996147884,"user_tz":-330,"elapsed":5727,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import time\n","import random\n","import sympy as sp\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","from sklearn.model_selection import train_test_split\n","plt.style.use('seaborn-whitegrid')\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading external modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"KItWEAxxe29F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616996265108,"user_tz":-330,"elapsed":26109,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}},"outputId":"05dc3a3d-636f-437e-9e69-2111c7d35536"},"source":["# Mount Google drive folder\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sj4QsiFnsl4X","executionInfo":{"status":"ok","timestamp":1616996269003,"user_tz":-330,"elapsed":2396,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}}},"source":["# Setup working directory and data directory\n","DIR = '/content/drive/My Drive/Colab Notebooks/EvenSem2021MAHE/Classifiers'\n","DATA_DIR = DIR + '/Data/SimulatedData/'\n","os.chdir(DIR)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"tZn3_Q38e29l","executionInfo":{"status":"ok","timestamp":1616996273254,"user_tz":-330,"elapsed":1680,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}}},"source":["# Function to simulate data\n","def GenerateSimulatedData(num_samples = 9000, num_features = 2, num_labels = 3):\n","    X = np.zeros((num_features, num_samples)) # data matrix (each column = single sample)\n","    y = np.zeros(num_samples, dtype = 'uint8') # class labels\n","    for j in range(num_labels):\n","      ix = range((num_samples//num_labels)*j, (num_samples//num_labels)*(j+1))\n","      r = np.linspace(0.0, 1.0, num_samples//num_labels) # radius\n","      t = np.linspace(j*4, (j+1)*4, num_samples//num_labels) +\\\n","       np.random.randn(num_samples//num_labels)*0.2 # theta\n","      X[:, ix] = np.vstack((r*np.sin(t), r*np.cos(t)))\n","      y[ix] = j\n","\n","    return X, y"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"fRjV4mhxnQUv","executionInfo":{"status":"ok","timestamp":1616996278867,"user_tz":-330,"elapsed":930,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}}},"source":["# Simulate data (this will later change to loading data from the DATA_DIR folder)\n","num_samples = 300\n","num_features = 2\n","num_labels = 3\n","X, y =  GenerateSimulatedData(num_samples, num_features, num_labels)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpG6hG0F0Xyz","executionInfo":{"status":"ok","timestamp":1616996281059,"user_tz":-330,"elapsed":1172,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}}},"source":["# Bias trick: append the bias dimension of ones to the data matrix so that the\n","# classifier can deal with a single weight matrix W.\n","X = np.vstack([X, np.ones((1, num_samples))])\n","num_features += 1"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2wKNjqNlghr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616996285404,"user_tz":-330,"elapsed":1153,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}},"outputId":"7ce1ba43-dd32-4dda-e756-4e4375310da6"},"source":["# Split data into train-validation-test sets\n","train_proportion = 0.7\n","validate_proportion = 0.2\n","idx = random.sample(np.arange(num_samples).tolist(), num_samples)\n","X_train, X_validate, X_test = \\\n","  np.split(X[:, idx],\n","           [int(train_proportion*num_samples),\n","            int((train_proportion+validate_proportion)*num_samples)],\n","           axis = 1)\n","\n","y_train, y_validate, y_test = \\\n","  np.split(y[idx], [int(train_proportion*num_samples),\n","            int((train_proportion+validate_proportion)*num_samples)])\n","\n","print('Training data size = %d'%(X_train.shape[1]))\n","print('Validation data size = %d'%(X_validate.shape[1]))\n","print('Test data size = %d'%(X_test.shape[1]))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Training data size = 210\n","Validation data size = 60\n","Test data size = 30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QQ5t8e-PH64p","executionInfo":{"status":"ok","timestamp":1616996291772,"user_tz":-330,"elapsed":2815,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}}},"source":["from LinearClassifiers.linear_classifier import *"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oyp4Xhrbts9u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616996293428,"user_tz":-330,"elapsed":1050,"user":{"displayName":"Sudarsan N.S Acharya","photoUrl":"","userId":"07498710390111180131"}},"outputId":"9597d07f-aac9-45df-ae0c-8ecf6fcbefd2"},"source":["softmaxclassifierObject = Softmax()\n","#softmaxclassifierObject = LinearSVM()\n","loss_hist = softmaxclassifierObject.train(X_train, y_train, learning_rate = 1e-0,\n","                                          reg = 1e-3, num_iters = 300,\n","                                          batch_size = 128, verbose = True)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Iteration: 0 / 300, Loss: 1.101371\n","Iteration: 10 / 300, Loss: 0.893127\n","Iteration: 20 / 300, Loss: 0.806388\n","Iteration: 30 / 300, Loss: 0.792027\n","Iteration: 40 / 300, Loss: 0.782225\n","Iteration: 50 / 300, Loss: 0.770568\n","Iteration: 60 / 300, Loss: 0.724405\n","Iteration: 70 / 300, Loss: 0.756020\n","Iteration: 80 / 300, Loss: 0.730247\n","Iteration: 90 / 300, Loss: 0.693905\n","Iteration: 100 / 300, Loss: 0.763590\n","Iteration: 110 / 300, Loss: 0.740124\n","Iteration: 120 / 300, Loss: 0.779818\n","Iteration: 130 / 300, Loss: 0.688423\n","Iteration: 140 / 300, Loss: 0.762572\n","Iteration: 150 / 300, Loss: 0.745677\n","Iteration: 160 / 300, Loss: 0.738659\n","Iteration: 170 / 300, Loss: 0.723538\n","Iteration: 180 / 300, Loss: 0.764119\n","Iteration: 190 / 300, Loss: 0.806379\n","Iteration: 200 / 300, Loss: 0.761869\n","Iteration: 210 / 300, Loss: 0.795389\n","Iteration: 220 / 300, Loss: 0.704899\n","Iteration: 230 / 300, Loss: 0.719670\n","Iteration: 240 / 300, Loss: 0.753902\n","Iteration: 250 / 300, Loss: 0.712212\n","Iteration: 260 / 300, Loss: 0.720083\n","Iteration: 270 / 300, Loss: 0.751495\n","Iteration: 280 / 300, Loss: 0.792544\n","Iteration: 290 / 300, Loss: 0.767572\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9poW8kANw1fy"},"source":["# A useful debugging strategy is to plot the loss as a function of\n","# iteration number:\n","plt.plot(loss_hist)\n","plt.xlabel('Iteration number')\n","plt.ylabel('Loss value')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"95BbBtIuw5hN"},"source":["# Evaluate performance on both the training and validation sets\n","y_train_pred = softmaxclassifierObject.predict(X_train)\n","print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n","y_validate_pred = softmaxclassifierObject.predict(X_validate)\n","print('validation accuracy: %f' % (np.mean(y_validate == y_validate_pred), ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbmldYeKFjz9"},"source":["# Get the learned weights and bias\n","W_learned = softmaxclassifierObject.W[:, :-1]\n","print('Learned weights =')\n","print(W_learned)\n","b_learned = softmaxclassifierObject.W[:, -1].reshape(num_labels,-1)\n","print('Learned bias =')\n","print(b_learned)\n","\n","# Function to extract correct category for each point (treated as a sample) in the 2D plane \n","f = lambda x1, x2: np.argmax(np.dot(W_learned, np.array([x1, x2])) + b_learned, axis = 0)\n","\n","# Generate 2D grid of points\n","x1, x2 = np.mgrid[np.min(X[0, :]) - 1:np.max(X[0, :]) + 1:1000j,\n","                  np.min(X[1, :]) - 1:np.max(X[1, :]) + 1:1000j]\n","\n","# Calculate category corresponding to each point on the grid\n","S = f(x1.flatten(), x2.flatten()).reshape(x1.shape)\n","\n","fig, ax = plt.subplots(1, 1, figsize = (6,6))\n","fig.tight_layout(pad = 4.0)\n","ax.contourf(x1, x2, S, cmap = plt.cm.Spectral, alpha = 0.8)\n","ax.scatter(X[0, :], X[1, :], c = y, s = 40, cmap = plt.cm.Spectral)\n","plt.xlim(x1.min(), x1.max())\n","plt.ylim(x2.min(), x2.max())\n","#fig.savefig('spiral_linear.png')\n"],"execution_count":null,"outputs":[]}]}